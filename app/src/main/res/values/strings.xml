<resources>
    <string name="app_name">ScrollApp</string>
    <string name="textview">
        <b>Computer science is the study of algorithmic processes, computational machines and computation itself.</b>[1] As a discipline, computer science spans a range of topics from theoretical studies of algorithms, computation and information to the practical issues of implementing computational systems in hardware and software.\n
        <b><i>Hello My name is Yugal.</i></b> \n

Its fields can be divided into theoretical and practical disciplines. For example, the theory of computation concerns abstract models of computation and general classes of problems that can be solved using them, while computer graphics or computational geometry emphasize more specific applications. \n Algorithms and data structures have been called the heart of computer science.[4] Programming language theory considers approaches to the description of computational processes, while computer programming involves the use of them to create complex systems. Computer architecture describes construction of computer components and computer-operated equipment. Artificial intelligence aims to synthesize goal-orientated processes such as problem-solving, decision-making, environmental adaptation, planning and learning found in humans and animals. A digital computer is capable of simulating various information processes.\n The fundamental concern of computer science is determining what can and cannot be automated.[6] Computer scientists usually focus on academic research. The Turing Award is generally recognized as the highest distinction in computer sciences.
        The earliest foundations of what would become computer science predate the invention of the modern digital computer. Machines for calculating fixed numerical tasks such as the abacus have existed since antiquity, aiding in computations such as multiplication and division. Algorithms for performing computations have existed since antiquity, even before the development of sophisticated computing equipment.\n

Wilhelm Schickard designed and constructed the first working mechanical calculator in 1623.[9] In 1673, Gottfried Leibniz demonstrated a digital mechanical calculator, called the Stepped Reckoner.[10] Leibniz may be considered the first computer scientist and information theorist, for, among other reasons, documenting the binary number system. In 1820, Thomas de Colmar launched the mechanical calculator industry[note 1] when he invented his simplified arithmometer, the first calculating machine strong enough and reliable enough to be used daily in an office environment. Charles Babbage started the design of the first automatic mechanical calculator, his Difference Engine, in 1822, which eventually gave him the idea of the first programmable mechanical calculator, his Analytical Engine.[11] He started developing this machine in 1834, and "in less than two years, he had sketched out many of the salient features of the modern computer".\n "A crucial step was the adoption of a punched card system derived from the Jacquard loom"[12] making it infinitely programmable.[note 2] In 1843, during the translation of a French article on the Analytical Engine, Ada Lovelace wrote, in one of the many notes she included, an algorithm to compute the Bernoulli numbers, which is considered to be the first published algorithm ever specifically tailored for implementation on a computer.[13] Around 1885, Herman Hollerith invented the tabulator, which used punched cards to process statistical information; eventually his company became part of IBM. Following Babbage, although unaware of his earlier work, Percy Ludgate in 1909 published [14] the 2nd of the only two designs for mechanical analytical engines in history. \n In 1937, one hundred years after Babbage\'s impossible dream, Howard Aiken convinced IBM, which was making all kinds of punched card equipment and was also in the calculator business[15] to develop his giant programmable calculator, the ASCC/Harvard Mark I, based on Babbage\'s Analytical Engine, which itself used cards and a central computing unit. \n When the machine was finished, some hailed it as "Babbage\'s dream come true".
    </string>
</resources>